{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 随机森林"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.创建对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('random_forest').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[rate_marriage: int, age: double, yrs_married: double, children: double, religious: int, affairs: int]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.csv('data/affairs.csv', inferSchema=True, header=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.数据分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6366, 6)\n"
     ]
    }
   ],
   "source": [
    "print((df.count(), len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- rate_marriage: integer (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- yrs_married: double (nullable = true)\n",
      " |-- children: double (nullable = true)\n",
      " |-- religious: integer (nullable = true)\n",
      " |-- affairs: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----+-----------+--------+---------+-------+\n",
      "|rate_marriage| age|yrs_married|children|religious|affairs|\n",
      "+-------------+----+-----------+--------+---------+-------+\n",
      "|            5|32.0|        6.0|     1.0|        3|      0|\n",
      "|            4|22.0|        2.5|     0.0|        2|      0|\n",
      "|            3|32.0|        9.0|     3.0|        3|      1|\n",
      "|            3|27.0|       13.0|     3.0|        1|      1|\n",
      "|            4|22.0|        2.5|     0.0|        1|      1|\n",
      "+-------------+----+-----------+--------+---------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+-----------------+------------------+------------------+\n",
      "|summary|     rate_marriage|               age|      yrs_married|          children|         religious|\n",
      "+-------+------------------+------------------+-----------------+------------------+------------------+\n",
      "|  count|              6366|              6366|             6366|              6366|              6366|\n",
      "|   mean| 4.109644989004084|29.082862079798932| 9.00942507068803|1.3968740182218033|2.4261702796104303|\n",
      "| stddev|0.9614295945655025| 6.847881883668817|7.280119972766412| 1.433470828560344|0.8783688402641785|\n",
      "|    min|                 1|              17.5|              0.5|               0.0|                 1|\n",
      "|    max|                 5|              42.0|             23.0|               5.5|                 4|\n",
      "+-------+------------------+------------------+-----------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().select('summary','rate_marriage','age','yrs_married', 'children', 'religious').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|affairs|count|\n",
      "+-------+-----+\n",
      "|      1| 2053|\n",
      "|      0| 4313|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('affairs').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|rate_marriage|count|\n",
      "+-------------+-----+\n",
      "|            1|   99|\n",
      "|            3|  993|\n",
      "|            5| 2684|\n",
      "|            4| 2242|\n",
      "|            2|  348|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('rate_marriage').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+-----+\n",
      "|affairs|rate_marriage|count|\n",
      "+-------+-------------+-----+\n",
      "|      0|            1|   25|\n",
      "|      1|            1|   74|\n",
      "|      0|            2|  127|\n",
      "|      1|            2|  221|\n",
      "|      0|            3|  446|\n",
      "|      1|            3|  547|\n",
      "|      0|            4| 1518|\n",
      "|      1|            4|  724|\n",
      "|      0|            5| 2197|\n",
      "|      1|            5|  487|\n",
      "+-------+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('affairs','rate_marriage').count().orderBy('rate_marriage','affairs','count', ascending=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----+\n",
      "|affairs|religious|count|\n",
      "+-------+---------+-----+\n",
      "|      0|        1|  613|\n",
      "|      1|        1|  408|\n",
      "|      0|        2| 1448|\n",
      "|      1|        2|  819|\n",
      "|      0|        3| 1715|\n",
      "|      1|        3|  707|\n",
      "|      0|        4|  537|\n",
      "|      1|        4|  119|\n",
      "+-------+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('affairs','religious').count().orderBy('religious','affairs','count', ascending=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-----+\n",
      "|affairs|children|count|\n",
      "+-------+--------+-----+\n",
      "|      0|     0.0| 1912|\n",
      "|      1|     0.0|  502|\n",
      "|      0|     1.0|  747|\n",
      "|      1|     1.0|  412|\n",
      "|      0|     2.0|  873|\n",
      "|      1|     2.0|  608|\n",
      "|      0|     3.0|  460|\n",
      "|      1|     3.0|  321|\n",
      "|      0|     4.0|  197|\n",
      "|      1|     4.0|  131|\n",
      "|      0|     5.5|  124|\n",
      "|      1|     5.5|   79|\n",
      "+-------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('affairs','children').count().orderBy('children','affairs','count', ascending=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+------------------+------------------+------------+\n",
      "|affairs|avg(rate_marriage)|          avg(age)|  avg(yrs_married)|     avg(children)|    avg(religious)|avg(affairs)|\n",
      "+-------+------------------+------------------+------------------+------------------+------------------+------------+\n",
      "|      1|3.6473453482708234|30.537018996590355|11.152459814905017|1.7289332683877252| 2.261568436434486|         1.0|\n",
      "|      0| 4.329700904242986| 28.39067934152562| 7.989334569904939|1.2388128912589844|2.5045212149316023|         0.0|\n",
      "+-------+------------------+------------------+------------------+------------------+------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('affairs').mean().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- rate_marriage: integer (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- yrs_married: double (nullable = true)\n",
      " |-- children: double (nullable = true)\n",
      " |-- religious: integer (nullable = true)\n",
      " |-- affairs: integer (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "df_assembler = VectorAssembler(inputCols=['rate_marriage', 'age', 'yrs_married', 'children', 'religious'], outputCol='features')\n",
    "df = df_assembler.transform(df)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-------+\n",
      "|features               |affairs|\n",
      "+-----------------------+-------+\n",
      "|[5.0,32.0,6.0,1.0,3.0] |0      |\n",
      "|[4.0,22.0,2.5,0.0,2.0] |0      |\n",
      "|[3.0,32.0,9.0,3.0,3.0] |1      |\n",
      "|[3.0,27.0,13.0,3.0,1.0]|1      |\n",
      "|[4.0,22.0,2.5,0.0,1.0] |1      |\n",
      "|[4.0,37.0,16.5,4.0,3.0]|1      |\n",
      "|[5.0,27.0,9.0,1.0,1.0] |1      |\n",
      "|[4.0,27.0,9.0,0.0,2.0] |1      |\n",
      "|[5.0,37.0,23.0,5.5,2.0]|1      |\n",
      "|[5.0,37.0,23.0,5.5,2.0]|1      |\n",
      "+-----------------------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['features','affairs']).show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = df.select(['features','affairs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4758\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = model_df.randomSplit([0.75,0.25])\n",
    "print(train_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|affairs|count|\n",
      "+-------+-----+\n",
      "|      1| 1515|\n",
      "|      0| 3243|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.groupBy('affairs').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|affairs|count|\n",
      "+-------+-----+\n",
      "|      1|  538|\n",
      "|      0| 1070|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df.groupBy('affairs').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rl_classifier = RandomForestClassifier(labelCol='affairs', numTrees=50).fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.测试数据评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-------+---------------------------------------+----------------------------------------+----------+\n",
      "|features               |affairs|rawPrediction                          |probability                             |prediction|\n",
      "+-----------------------+-------+---------------------------------------+----------------------------------------+----------+\n",
      "|[1.0,22.0,2.5,0.0,1.0] |1      |[15.703172001412614,34.29682799858739] |[0.31406344002825226,0.6859365599717477]|1.0       |\n",
      "|[1.0,22.0,2.5,1.0,1.0] |1      |[15.685716111714266,34.314283888285736]|[0.3137143222342853,0.6862856777657147] |1.0       |\n",
      "|[1.0,22.0,2.5,1.0,2.0] |0      |[16.178993949848483,33.82100605015152] |[0.32357987899696966,0.6764201210030304]|1.0       |\n",
      "|[1.0,22.0,2.5,1.0,2.0] |0      |[16.178993949848483,33.82100605015152] |[0.32357987899696966,0.6764201210030304]|1.0       |\n",
      "|[1.0,22.0,2.5,1.0,3.0] |1      |[20.12165229148593,29.87834770851407]  |[0.4024330458297186,0.5975669541702814] |1.0       |\n",
      "|[1.0,27.0,2.5,0.0,1.0] |0      |[15.868178035686299,34.1318219643137]  |[0.31736356071372596,0.682636439286274] |1.0       |\n",
      "|[1.0,27.0,2.5,0.0,2.0] |1      |[16.154681658874704,33.8453183411253]  |[0.32309363317749407,0.6769063668225059]|1.0       |\n",
      "|[1.0,27.0,6.0,1.0,3.0] |0      |[16.686649259318948,33.31335074068105] |[0.33373298518637895,0.666267014813621] |1.0       |\n",
      "|[1.0,27.0,9.0,2.0,2.0] |1      |[12.574607254483158,37.42539274551684] |[0.25149214508966317,0.7485078549103368]|1.0       |\n",
      "|[1.0,32.0,13.0,2.0,2.0]|1      |[12.604149792501499,37.395850207498505]|[0.25208299585002997,0.7479170041499701]|1.0       |\n",
      "|[1.0,32.0,13.0,2.0,2.0]|1      |[12.604149792501499,37.395850207498505]|[0.25208299585002997,0.7479170041499701]|1.0       |\n",
      "|[1.0,32.0,13.0,2.0,2.0]|1      |[12.604149792501499,37.395850207498505]|[0.25208299585002997,0.7479170041499701]|1.0       |\n",
      "|[1.0,32.0,13.0,3.0,3.0]|1      |[14.287754124795635,35.712245875204374]|[0.28575508249591264,0.7142449175040874]|1.0       |\n",
      "|[1.0,32.0,16.5,2.0,3.0]|1      |[12.07375624070556,37.92624375929445]  |[0.24147512481411113,0.7585248751858888]|1.0       |\n",
      "|[1.0,32.0,16.5,4.0,3.0]|0      |[13.472572379531831,36.527427620468174]|[0.2694514475906366,0.7305485524093633] |1.0       |\n",
      "|[1.0,37.0,16.5,1.0,3.0]|1      |[13.432232441217415,36.56776755878259] |[0.2686446488243483,0.7313553511756518] |1.0       |\n",
      "|[1.0,37.0,16.5,2.0,3.0]|1      |[13.091430773976917,36.90856922602309] |[0.2618286154795383,0.7381713845204617] |1.0       |\n",
      "|[1.0,37.0,16.5,3.0,2.0]|1      |[10.797878484441904,39.20212151555809] |[0.2159575696888381,0.7840424303111619] |1.0       |\n",
      "|[1.0,37.0,16.5,3.0,2.0]|1      |[10.797878484441904,39.20212151555809] |[0.2159575696888381,0.7840424303111619] |1.0       |\n",
      "|[1.0,37.0,16.5,4.0,2.0]|1      |[11.83295579124884,38.16704420875116]  |[0.2366591158249768,0.7633408841750231] |1.0       |\n",
      "+-----------------------+-------+---------------------------------------+----------------------------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rl_predictions = rl_classifier.transform(test_df)\n",
    "rl_predictions.show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|       0.0| 1294|\n",
      "|       1.0|  314|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rl_predictions.groupBy('prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71%\n"
     ]
    }
   ],
   "source": [
    "rl_accuracy = MulticlassClassificationEvaluator(labelCol='affairs', metricName='accuracy').evaluate(rl_predictions)\n",
    "print('{0:.0%}'.format(rl_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69%\n"
     ]
    }
   ],
   "source": [
    "rl_precision = MulticlassClassificationEvaluator(labelCol='affairs', metricName='weightedPrecision').evaluate(rl_predictions)\n",
    "print('{0:.0%}'.format(rl_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC曲线下的面积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.50%\n"
     ]
    }
   ],
   "source": [
    "rl_auc = BinaryClassificationEvaluator(labelCol='affairs').evaluate(rl_predictions)\n",
    "print('{0:.2%}'.format(rl_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(5, {0: 0.5858, 1: 0.03, 2: 0.2539, 3: 0.0454, 4: 0.0849})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rl_classifier.featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'numeric': [{'idx': 0, 'name': 'rate_marriage'},\n",
       "  {'idx': 1, 'name': 'age'},\n",
       "  {'idx': 2, 'name': 'yrs_married'},\n",
       "  {'idx': 3, 'name': 'children'},\n",
       "  {'idx': 4, 'name': 'religious'}]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema['features'].metadata['ml_attr']['attrs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassificationModel\n",
    "rl_classifier.save('data/rf_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl = RandomForestClassificationModel.load('data/rf_model')\n",
    "new_preditions = rl.transform(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-------+---------------------------------------+----------------------------------------+----------+\n",
      "|features              |affairs|rawPrediction                          |probability                             |prediction|\n",
      "+----------------------+-------+---------------------------------------+----------------------------------------+----------+\n",
      "|[1.0,17.5,0.5,0.0,2.0]|0      |[42.72903564356653,7.270964356433465]  |[0.8545807128713306,0.1454192871286693] |0.0       |\n",
      "|[1.0,22.0,2.5,0.0,1.0]|1      |[15.703172001412614,34.29682799858739] |[0.31406344002825226,0.6859365599717477]|1.0       |\n",
      "|[1.0,22.0,2.5,0.0,2.0]|1      |[16.324302953793563,33.67569704620644] |[0.32648605907587125,0.6735139409241288]|1.0       |\n",
      "|[1.0,22.0,2.5,1.0,1.0]|1      |[15.685716111714266,34.314283888285736]|[0.3137143222342853,0.6862856777657147] |1.0       |\n",
      "|[1.0,22.0,2.5,1.0,2.0]|1      |[16.178993949848483,33.82100605015152] |[0.32357987899696966,0.6764201210030304]|1.0       |\n",
      "|[1.0,22.0,2.5,1.0,3.0]|0      |[20.12165229148593,29.87834770851407]  |[0.4024330458297186,0.5975669541702814] |1.0       |\n",
      "|[1.0,27.0,2.5,0.0,2.0]|1      |[16.154681658874704,33.8453183411253]  |[0.32309363317749407,0.6769063668225059]|1.0       |\n",
      "|[1.0,27.0,2.5,0.0,2.0]|1      |[16.154681658874704,33.8453183411253]  |[0.32309363317749407,0.6769063668225059]|1.0       |\n",
      "|[1.0,27.0,2.5,1.0,3.0]|1      |[17.128213225908393,32.87178677409161] |[0.34256426451816785,0.6574357354818322]|1.0       |\n",
      "|[1.0,27.0,6.0,0.0,2.0]|0      |[18.019966562503182,31.980033437496818]|[0.3603993312500636,0.6396006687499364] |1.0       |\n",
      "|[1.0,27.0,6.0,1.0,1.0]|1      |[16.849517888319415,33.150482111680596]|[0.3369903577663882,0.6630096422336117] |1.0       |\n",
      "|[1.0,27.0,6.0,1.0,2.0]|0      |[16.407379059786965,33.592620940213045]|[0.3281475811957392,0.6718524188042607] |1.0       |\n",
      "|[1.0,27.0,6.0,1.0,2.0]|0      |[16.407379059786965,33.592620940213045]|[0.3281475811957392,0.6718524188042607] |1.0       |\n",
      "|[1.0,27.0,6.0,1.0,3.0]|1      |[16.686649259318948,33.31335074068105] |[0.33373298518637895,0.666267014813621] |1.0       |\n",
      "|[1.0,27.0,6.0,2.0,2.0]|1      |[15.752337825767109,34.24766217423289] |[0.3150467565153422,0.6849532434846579] |1.0       |\n",
      "|[1.0,27.0,6.0,2.0,2.0]|1      |[15.752337825767109,34.24766217423289] |[0.3150467565153422,0.6849532434846579] |1.0       |\n",
      "|[1.0,27.0,6.0,2.0,3.0]|1      |[16.057020936416485,33.94297906358352] |[0.32114041872832966,0.6788595812716703]|1.0       |\n",
      "|[1.0,27.0,6.0,3.0,1.0]|0      |[18.48647792818585,31.513522071814148] |[0.369729558563717,0.630270441436283]   |1.0       |\n",
      "|[1.0,27.0,9.0,1.0,3.0]|1      |[14.34953308460231,35.6504669153977]   |[0.2869906616920461,0.7130093383079538] |1.0       |\n",
      "|[1.0,27.0,9.0,4.0,1.0]|0      |[19.440149453768647,30.559850546231353]|[0.388802989075373,0.6111970109246271]  |1.0       |\n",
      "+----------------------+-------+---------------------------------------+----------------------------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_preditions.show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark-2.3.2",
   "language": "python",
   "name": "pyspark-2.3.2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
